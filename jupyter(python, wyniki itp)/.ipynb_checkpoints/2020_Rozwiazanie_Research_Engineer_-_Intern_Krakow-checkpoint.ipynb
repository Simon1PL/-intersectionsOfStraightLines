{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lj7hNcao0U9L"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mnist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3dfda8f0857d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_data\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MNIST\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# loading the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mnist'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "m=input_data.read_data_sets(\"MNIST\")\n",
    "# loading the data\n",
    "data = MNIST(r'data')\n",
    "images, labels = data.load_training()\n",
    "im_test, lab_test = data.load_testing()\n",
    "\n",
    "# set of hyperparameters for better results \n",
    "LEARNING_RATES = [0.001, 0.003, 0.01]\n",
    "ITERATIONSS = [5, 10, 20]\n",
    "BATCH_SIZES = [1, 32, 128]\n",
    "BETAS = [0.9, 0.95]\n",
    "\n",
    "# cleaning the data\n",
    "def preprocess_data(x, y):\n",
    "    print('preprocessing {} samples'.format(len(x)))\n",
    "    indexes = []\n",
    "    cleaned_labels = []\n",
    "    for idx, val in enumerate(y):\n",
    "        if val is not 0 and val is not 1:\n",
    "            indexes.append(idx)\n",
    "            if val in [2, 3, 5, 7]:\n",
    "                cleaned_labels.append(1)  # prime number 1\n",
    "            else:\n",
    "                cleaned_labels.append(0)  # else   0\n",
    "\n",
    "    cleaned_imgs = [x[i] for i in indexes]\n",
    "    for image in cleaned_imgs:\n",
    "        for idx in range(len(image)):\n",
    "            image[idx] /= 255\n",
    "\n",
    "    return cleaned_imgs, cleaned_labels\n",
    "\n",
    "# actual model\n",
    "class Model:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.values = np.zeros((1, 785), dtype=float)\n",
    "\n",
    "    def fit(self, x, y) -> None:\n",
    "        for it in range(ITERATIONS):\n",
    "            print('iteration no.: {} ...'.format(it+1))\n",
    "            x_batches, y_batches = self.random_data_shuffle(x, y)\n",
    "            n = len(x)\n",
    "            x_batches = [x_batches[k:k + BATCH_SIZE] for k in range(0, n, BATCH_SIZE)]\n",
    "            y_batches = [y_batches[k:k + BATCH_SIZE] for k in range(0, n, BATCH_SIZE)]\n",
    "            for xx, yy in zip(x_batches, y_batches):\n",
    "                update = np.zeros((785, 1))\n",
    "                vt = np.zeros(self.values.shape)\n",
    "                for number, label in zip(xx, yy):\n",
    "                    number = np.insert(number, 0, 1).reshape(785, 1)\n",
    "                    poly = np.dot(self.values, number)\n",
    "                    val = self.sigmoid(poly)\n",
    "                    update += self.cost_derivative(label, val, number)\n",
    "                update = np.array(update).reshape(1, 785)/len(xx)\n",
    "                for index in range(len(update)):\n",
    "                    vt[index] = BETA*vt[index]+LEARNING_RATE*update[index]\n",
    "                    self.values += update\n",
    "\n",
    "    def predict(self, x) -> np.ndarray:\n",
    "        print('predicting {} values ...'.format(len(x)))\n",
    "        vals = []\n",
    "        for number in x:\n",
    "            number = np.insert(number, 0, 1).reshape(785, 1)\n",
    "            poly = np.dot(self.values, number)\n",
    "            val = self.sigmoid(poly)\n",
    "            vals.append(val)\n",
    "        return np.rint(vals)\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(y_true, y_pred) -> float:\n",
    "        counter = 0\n",
    "        for x, y in zip(y_true, y_pred):\n",
    "            counter += 1 if x == y else 0\n",
    "        return counter/len(y_pred)\n",
    "\n",
    "    @staticmethod\n",
    "    def random_data_shuffle(x, y):\n",
    "        index = [i for i in range(len(x))]\n",
    "        np.random.shuffle(index)\n",
    "        x_shuffled = [x[i] for i in index]\n",
    "        y_shuffled = [y[i] for i in index]\n",
    "        return x_shuffled, y_shuffled\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    @staticmethod\n",
    "    def cost_derivative(x, y, f):\n",
    "        return (x - y)*f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xonYFuEw2CDp"
   },
   "outputs": [],
   "source": [
    "# cleaning our dataset\n",
    "images, labels = preprocess_data(images, labels)\n",
    "im_test, lab_test = preprocess_data(im_test, lab_test)\n",
    "\n",
    "# storing all results in .txt file\n",
    "f = open('Results.txt', 'a')\n",
    "for q in LEARNING_RATES:\n",
    "    for w in ITERATIONSS:\n",
    "        for e in BATCH_SIZES:\n",
    "            for r in BETAS:\n",
    "                LEARNING_RATE = q\n",
    "                ITERATIONS = w\n",
    "                BATCH_SIZE = e\n",
    "                BETA = r\n",
    "                m = Model()\n",
    "                m.fit(images, labels)\n",
    "                v = m.predict(im_test)\n",
    "                score = m.evaluate(lab_test, v)\n",
    "                f.write('#'*40)\n",
    "                f.write('\\nlearning rate: {}\\niterations: {}\\nbatch size: {}\\nbeta: {}\\nSCORE: {}\\n'.format(q, w, e, r, score))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pxQntV5Ik5yM"
   },
   "source": [
    "# **Podsumowanie**:\n",
    "\n",
    "Wynik stworzonego modelu zależy od poprawnego dobrania hiperparametrów. \n",
    "Poprawność przewidywania na zbiorze walidacyjnym waha się średnio między 60% a 90%.\n",
    "\n",
    "**LEARNING RATE** - od tej wartości zależy jak szyko będą się zmieniać parametry (self.values) w naszym modelu. \n",
    "Mniejszy LEARNING RATE pozwala na płynniejsze uzyskanie oczekiwanych wartości,\n",
    "ale spowalnia proces uczenia się. \n",
    "\n",
    "**ITERATIONS** - czyli ile razy nasz model 'zobaczy' te same dane,\n",
    "ta liczba nie może być zbyt wielka, inaczej wystąpi zjawisko overfittingu.\n",
    "\n",
    "**BATCH SIZE** - ilość danych w pojedyńczej serii, z której policzny zostanie gradient.\n",
    "\n",
    "**BETA** - parametr wykorzystywany w SGD z momentum zprzedziału [0, 1].\n",
    "\n",
    "Najlepszy wynik jaki udało mi się uzyskać dla parametrów:\n",
    "\n",
    "LEARNING_RATE = 0.001,\n",
    "\n",
    "ITERATIONS = 5,\n",
    "\n",
    "BATCH_SIZE = 128,\n",
    "\n",
    "BETA = 0.9,\n",
    "\n",
    "to ponad 92%. Liczba iteracji mogłaby być troszkę większa i nie wpłynęłoby to znacząco na ostateczny wynik.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
